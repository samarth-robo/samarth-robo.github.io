<!DOCTYPE html>
<html lang="en">
  <script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
  <script src="../navbar.js"></script>
  <script src="../footer.js"></script>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Samarth - ESE650</title>

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
  </head>

  <body onload="create_navbar('../'); create_footer();">
    <div class="container">
      <div class="row">
        <div class="col">
          <h1>Learning in Robotics - ESE 650</h1>
        </div>
      </div> 
       <div class="row">
        <div class="col-md-7 align-self-center">
          <h2>Color image panorama using orientation tracking</h2>
          <p>For this project, images were recoreded using a camera mounted on a plate with an IMU. The challenge was to organize the images into a panorama using Unscented Kalman Filter based orientation tracking.</p>
          <p><a class="btn btn-primary" href="https://bitbucket.org/samarthb/kalman-orientation-tracking/wiki/Home" role="button">Learn more</a></p>
        </div>
        <div class="col-md-5 align-self-center">
            <iframe height="300" class="w-100" src="http://www.youtube.com/embed/KxkIF6efAJA?start=37" frameborder="0" allowfullscreen></iframe>
        </div>
      </div>
      <hr class="featurette-divider">
      
      <div class="row">
        <div class="col-md-5 align-self-center">
            <a href="https://bitbucket.org/samarthb/ese650-project4/wiki/Home"><img class="w-100 img-responsive align-middle" src="ese650_slam.jpg" alt="SLAM"></a>
        </div>
        <div class="col-md-7 align-self-center">
          <h2>Simultaneous Localization and Mapping using a particle filter</h2>
          <p>This project used LIDAR and wheel odometry data recorded using a mobile robot to create a planar map of the path followed by the robot and simultaneously localized the robot in that map. After the map was constructed, RANSAC was used to extract the ground plane from Kinect disparity data and the ground plane pixels were overlaid on the SLAM planar map.</p>
          <p><a class="btn btn-primary" href="https://bitbucket.org/samarthb/ese650-project4/wiki/Home" role="button">Learn more</a></p>
        </div>
      </div>
      <hr class="featurette-divider">
      
      <div class="row">
        <div class="col-md-7 align-self-center">
          <h2>Point Cloud registration for 3D mapping</h2>
          <p>In this project I implemented an efficient 3D point-cloud registration pipeline based on 3D feature matching using the Point Cloud Library that could handle large differences in position and orientation between the two point clouds.</p>
          <p><a class="btn btn-primary" href="https://bitbucket.org/samarthb/3d-slam/wiki/Home" role="button">Learn more</a></p>
        </div>
        <div class="col-md-5 align-self-center">
            <a href="https://bitbucket.org/samarthb/3d-slam/wiki/Home"><img class="w-100 img-responsive align-middle" src="ese650_registration.jpg" alt="3d Point Cloud registration"></a>
        </div>
      </div>
      <hr class="featurette-divider">
      
      <div class="row">
        <div class="col-md-5 align-self-center">
            <a href="https://bitbucket.org/samarthb/ese650-project-5/wiki/Home"><img class="w-100 img-responsive align-middle" src="ese650_imitation.jpg" alt="Path planning using imitation learning"></a>
        </div>
        <div class="col-md-7 align-self-center">
          <h2 class="featurette-heading">Path planning for a robotic vehicle using imitation learning</h2>
          <p class="lead">In this project I used imitation learning to learn a cost map on an aerial photograph for a robotic car travelling through a city and used the A* algorithm to plan the path for the car.</p>
          <p><a class="btn btn-primary" href="https://bitbucket.org/samarthb/ese650-project-5/wiki/Home" role="button">Learn more</a></p>
        </div>
      </div>
      <hr class="featurette-divider">
      
      <div class="row">
        <div class="col-md-7 align-self-center">
          <h2>Probabilistic color segmentation of images</h2>
          <p>In this project I trained Gaussian Mixture Models to segment a red barrel out of color images under different illumination conditions.</p>
          <p><a class="btn btn-primary" href="https://bitbucket.org/samarthb/ese650-project-1/wiki/Home" role="button">Learn more</a></p>
        </div>
        <div class="col-md-5 align-self-center">
            <a href="https://bitbucket.org/samarthb/ese650-project-1/wiki/Home"><img class="w-100 img-responsive align-middle" src="ese650_color.jpg" alt="Probabilistic Color Segmentation"></a>
        </div>
      </div>
      <hr class="featurette-divider">

      <div class="row">
        <div class="col-md-5 align-self-center">
            <img class="w-100 img-responsive align-middle" src="ese650_hmm.jpg" alt="Hidden Markov Models"></a>
        </div>
        <div class="col-md-7 align-self-center">
          <h2>Gesture recognition using Hidden Markov Models</h2>
          <p>In this project I recognized gestures from among a collection of 6 gestures using IMU data with the help of Hidden Markov Models. I first clustered the 6 channel IMU data into 20 clusters and then trained a different HMM for every gesture, using cross-validation for determining the number of hidden states.</p>
        </div>
      </div>
      <!-- /END THE FEATURETTES -->


      <!-- FOOTER -->
      <footer id="myfooter">
      </footer>

    </div><!-- /.container -->


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://code.jquery.com/jquery-1.10.2.min.js"></script>
    <script src="../bootstrap/dist/js/bootstrap.min.js"></script>
    <script src="../bootstrap/docs-assets/js/holder.js"></script>
  </body>
</html>
